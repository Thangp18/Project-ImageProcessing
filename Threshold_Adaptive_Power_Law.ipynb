{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd588045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import sobel\n",
    "import time\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05cc87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set better plotting defaults for Jupyter\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0576a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
      "â•‘       TAPLA Image Enhancement - Jupyter Notebook Version             â•‘\n",
      "â•‘  Threshold-based Adaptive Power-Law Applications                     â•‘\n",
      "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "\n",
      "Quick Start Examples:\n",
      "\n",
      "1. BATCH PROCESSING (1000 images):\n",
      "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   # Process entire folder\n",
      "   results = batch_enhance_images(\n",
      "       input_folder='./input_images',\n",
      "       output_folder='./enhanced_images',\n",
      "       c=1.5, gamma=0.56, k=2.0, k1=0.2,\n",
      "       color=True  # Set False for grayscale\n",
      "   )\n",
      "\n",
      "   # Preview results\n",
      "   preview_batch_results('./enhanced_images', num_samples=6)\n",
      "\n",
      "   # Compare original vs enhanced\n",
      "   compare_batch_results('./input_images', './enhanced_images', num_samples=3)\n",
      "\n",
      "2. Upload and enhance single image (Google Colab):\n",
      "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   filename = upload_image_jupyter()\n",
      "\n",
      "   # For COLOR image:\n",
      "   img = load_image(filename, color=True)\n",
      "   enhanced, metrics = run_tapla_experiment(img, c=1.5, gamma=0.56, k=2.0, k1=0.2)\n",
      "\n",
      "2. Use sample images (no upload needed):\n",
      "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   # Create test dataset\n",
      "   create_sample_dataset('./test_images', num_images=10)\n",
      "\n",
      "   # Process all images\n",
      "   results = batch_enhance_images('./test_images', './output', color=True)\n",
      "\n",
      "3. Compare multiple parameter sets:\n",
      "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "   img = load_image('image.jpg', color=True)\n",
      "   params_list = [\n",
      "       {'c': 1.0, 'gamma': 2.5, 'k': 2.0, 'k1': 0.06, 'window_size': 11},\n",
      "       {'c': 1.0, 'gamma': 1.1, 'k': 4.0, 'k1': 0.06, 'window_size': 11},\n",
      "       {'c': 2.0, 'gamma': 1.5, 'k': -1.0, 'k1': 0.1, 'window_size': 11}\n",
      "   ]\n",
      "   results = compare_multiple_params(img, params_list)\n",
      "\n",
      "BATCH PROCESSING TIPS:\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
      "â€¢ Supports: .jpg, .jpeg, .png, .bmp\n",
      "â€¢ Auto-saves metrics to CSV\n",
      "â€¢ Progress bar shows real-time status\n",
      "â€¢ Handles errors gracefully\n",
      "â€¢ Creates output folder automatically\n",
      "\n",
      "Parameter Guide:\n",
      "   c      : brightness (typically 1.0-2.0)\n",
      "   gamma  : contrast (>1 increase, <1 decrease)\n",
      "   k      : sharpness (positive) or smoothness (negative)\n",
      "   k1     : threshold control [0, 1]\n",
      "\n",
      "Ready to use! ğŸš€\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class TAPLAImageEnhancement:\n",
    "    \"\"\"\n",
    "    Threshold-based Adaptive Power-Law Applications (TAPLA) \n",
    "    for Image Enhancement\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, c=1.0, gamma=1.5, k=2.0, k1=0.1, window_size=11):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - c: brightness control parameter\n",
    "        - gamma: contrast control parameter  \n",
    "        - k: sharpness/smoothness control parameter\n",
    "        - k1: threshold adaptation control [0,1]\n",
    "        - window_size: local window size (must be odd)\n",
    "        \"\"\"\n",
    "        self.c = c\n",
    "        self.gamma = gamma\n",
    "        self.k = k\n",
    "        self.k1 = k1\n",
    "        self.w = window_size if window_size % 2 == 1 else window_size + 1\n",
    "        \n",
    "    def compute_integral_average_image(self, img):\n",
    "        \"\"\"\n",
    "        Compute integral average image - Equations (3-5)\n",
    "        \"\"\"\n",
    "        m, n = img.shape\n",
    "        g = img.astype(np.float64).copy()\n",
    "        \n",
    "        # First row - Equation (3)\n",
    "        for y in range(1, n):\n",
    "            g[0, y] = (g[0, y-1] * y + g[0, y]) / (y + 1)\n",
    "        \n",
    "        # First column - Equation (4)\n",
    "        for x in range(1, m):\n",
    "            g[x, 0] = (g[x-1, 0] * x + g[x, 0]) / (x + 1)\n",
    "        \n",
    "        # Other points - Equation (5)\n",
    "        for x in range(1, m):\n",
    "            for y in range(1, n):\n",
    "                r, c_idx = x - 1, y - 1\n",
    "                g[x, y] = (g[x, y] + \n",
    "                          g[r, y] * r * (y + 1) + \n",
    "                          g[x, c_idx] * c_idx * (x + 1) - \n",
    "                          g[r, c_idx] * r * c_idx) / ((x + 1) * (y + 1))\n",
    "        \n",
    "        return g\n",
    "    \n",
    "    def compute_local_mean(self, integral_avg_img, x, y, m, n):\n",
    "        \"\"\"\n",
    "        Compute local mean using integral average - Equations (6-7)\n",
    "        \"\"\"\n",
    "        d = (self.w - 1) // 2\n",
    "        \n",
    "        x1 = max(0, x - d - 1)\n",
    "        y1 = max(0, y - d - 1)\n",
    "        x2 = min(m - 1, x + d)\n",
    "        y2 = min(n - 1, y + d)\n",
    "        \n",
    "        s = (integral_avg_img[x2, y2] * (x2 + 1) * (y2 + 1))\n",
    "        \n",
    "        if x1 > 0 and y1 > 0:\n",
    "            s += (integral_avg_img[x1, y1] * (x1 + 1) * (y1 + 1))\n",
    "        \n",
    "        if x1 > 0:\n",
    "            s -= (integral_avg_img[x1, y2] * (x1 + 1) * (y2 + 1))\n",
    "        \n",
    "        if y1 > 0:\n",
    "            s -= (integral_avg_img[x2, y1] * (x2 + 1) * (y1 + 1))\n",
    "        \n",
    "        actual_w = (x2 - x1) * (y2 - y1)\n",
    "        local_mean = s / max(actual_w, 1)\n",
    "        \n",
    "        return local_mean\n",
    "    \n",
    "    def compute_threshold(self, intensity, local_mean):\n",
    "        \"\"\"\n",
    "        Compute local threshold - Equation (9)\n",
    "        \"\"\"\n",
    "        delta = abs(intensity - local_mean)\n",
    "        denominator = max(1 - delta, 1e-10)\n",
    "        threshold = local_mean * (1 + self.k1 * (delta / denominator) - 1)\n",
    "        return threshold\n",
    "    \n",
    "    def tapla_transform(self, img):\n",
    "        \"\"\"\n",
    "        Apply TAPLA transformation - Equations (12) and (15)\n",
    "        \"\"\"\n",
    "        img_norm = img.astype(np.float64) / 255.0\n",
    "        m, n = img_norm.shape\n",
    "        \n",
    "        integral_avg = self.compute_integral_average_image(img_norm)\n",
    "        output = np.zeros_like(img_norm)\n",
    "        \n",
    "        for x in range(m):\n",
    "            for y in range(n):\n",
    "                r = img_norm[x, y]\n",
    "                local_mean = self.compute_local_mean(integral_avg, x, y, m, n)\n",
    "                T = self.compute_threshold(r, local_mean)\n",
    "                d = r - T\n",
    "                \n",
    "                power = self.gamma * (1 - self.k * d)\n",
    "                coefficient = self.c * (1 + self.k * d)\n",
    "                \n",
    "                if r > 0:\n",
    "                    s = coefficient * (r ** power)\n",
    "                else:\n",
    "                    s = 0\n",
    "                \n",
    "                output[x, y] = np.clip(s, 0, 1)\n",
    "        \n",
    "        return (output * 255).astype(np.uint8)\n",
    "    \n",
    "    def calculate_eme(self, img, block_size=8):\n",
    "        \"\"\"\n",
    "        Calculate EME - Equation (16)\n",
    "        \"\"\"\n",
    "        m, n = img.shape\n",
    "        p = m // block_size\n",
    "        q = n // block_size\n",
    "        \n",
    "        eme = 0\n",
    "        e = 1e-10\n",
    "        \n",
    "        for i in range(p):\n",
    "            for j in range(q):\n",
    "                block = img[i*block_size:(i+1)*block_size, \n",
    "                           j*block_size:(j+1)*block_size]\n",
    "                \n",
    "                I_max = np.max(block) + e\n",
    "                I_min = np.min(block) + e\n",
    "                \n",
    "                if I_max > 0:\n",
    "                    eme += np.log(I_max / I_min)\n",
    "        \n",
    "        return eme / (p * q)\n",
    "    \n",
    "    def calculate_tenengrad(self, img):\n",
    "        \"\"\"\n",
    "        Calculate Tenengrad - Equations (17-18)\n",
    "        \"\"\"\n",
    "        Gx = sobel(img.astype(np.float64), axis=1)\n",
    "        Gy = sobel(img.astype(np.float64), axis=0)\n",
    "        s = np.sqrt(Gx**2 + Gy**2)\n",
    "        return np.sum(s**2)\n",
    "    \n",
    "    def enhance_image(self, img):\n",
    "        \"\"\"\n",
    "        Main enhancement method\n",
    "        Supports both grayscale and color images\n",
    "        For color images, each channel (R, G, B) is processed separately\n",
    "        \"\"\"\n",
    "        if len(img.shape) == 3:\n",
    "            # Color image - process each channel separately\n",
    "            print(\"ğŸ¨ Processing color image (R, G, B channels separately)...\")\n",
    "            output = np.zeros_like(img)\n",
    "            for c in range(3):\n",
    "                print(f\"   Channel {['R', 'G', 'B'][c]}...\", end=' ')\n",
    "                output[:, :, c] = self.tapla_transform(img[:, :, c])\n",
    "                print(\"âœ“\")\n",
    "            return output\n",
    "        else:\n",
    "            # Grayscale image\n",
    "            print(\"â¬œ Processing grayscale image...\")\n",
    "            return self.tapla_transform(img)\n",
    "\n",
    "\n",
    "def upload_image_jupyter():\n",
    "    \"\"\"\n",
    "    Upload image in Jupyter Notebook\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try Google Colab first\n",
    "        from google.colab import files\n",
    "        print(\"ğŸ“¤ Click 'Choose Files' to upload your image...\")\n",
    "        uploaded = files.upload()\n",
    "        filename = list(uploaded.keys())[0]\n",
    "        print(f\"âœ“ Uploaded: {filename}\")\n",
    "        return filename\n",
    "    except:\n",
    "        # For regular Jupyter\n",
    "        print(\"ğŸ“ Please use: img = load_image('path/to/your/image.jpg')\")\n",
    "        print(\"   Or place your image in the same folder and use: img = load_image('image.jpg')\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_image(path, color=False):\n",
    "    \"\"\"\n",
    "    Load image from path\n",
    "    \n",
    "    Parameters:\n",
    "        path: image file path\n",
    "        color: True for color image, False for grayscale\n",
    "    \n",
    "    Examples:\n",
    "        img = load_image('image.jpg')  # Grayscale\n",
    "        img = load_image('image.jpg', color=True)  # Color (RGB)\n",
    "    \"\"\"\n",
    "    if color:\n",
    "        img = cv2.imread(path)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            print(f\"âœ“ Color image loaded: {img.shape}\")\n",
    "    else:\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            print(f\"âœ“ Grayscale image loaded: {img.shape}\")\n",
    "    \n",
    "    if img is None:\n",
    "        raise ValueError(f\"âŒ Could not load image from: {path}\\n\"\n",
    "                        f\"   Check if:\\n\"\n",
    "                        f\"   1. File exists at that location\\n\"\n",
    "                        f\"   2. Path is correct (use forward slashes /)\\n\"\n",
    "                        f\"   3. File format is supported (jpg, png, bmp, etc.)\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def batch_enhance_images(input_folder, output_folder, c=1.0, gamma=1.5, k=2.0, \n",
    "                         k1=0.1, window_size=11, color=False, \n",
    "                         file_extensions=['*.jpg', '*.jpeg', '*.png', '*.bmp'],\n",
    "                         save_metrics=True):\n",
    "    \"\"\"\n",
    "    Batch process multiple images from a folder\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder: path to folder containing input images\n",
    "        output_folder: path to save enhanced images\n",
    "        c, gamma, k, k1, window_size: TAPLA parameters\n",
    "        color: True for color images, False for grayscale\n",
    "        file_extensions: list of file patterns to process\n",
    "        save_metrics: save metrics to CSV file\n",
    "    \n",
    "    Returns:\n",
    "        results: dictionary with processing statistics\n",
    "    \n",
    "    Example:\n",
    "        results = batch_enhance_images(\n",
    "            input_folder='./input_images',\n",
    "            output_folder='./enhanced_images',\n",
    "            c=1.5, gamma=0.56, k=2.0, k1=0.2,\n",
    "            color=True\n",
    "        )\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output folder if not exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = []\n",
    "    for ext in file_extensions:\n",
    "        image_files.extend(glob.glob(os.path.join(input_folder, ext)))\n",
    "        image_files.extend(glob.glob(os.path.join(input_folder, ext.upper())))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"âŒ No images found in {input_folder}\")\n",
    "        print(f\"   Looking for: {file_extensions}\")\n",
    "        return None\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"BATCH TAPLA IMAGE ENHANCEMENT\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ“ Input folder:  {input_folder}\")\n",
    "    print(f\"ğŸ“ Output folder: {output_folder}\")\n",
    "    print(f\"ğŸ–¼ï¸  Found {len(image_files)} images\")\n",
    "    print(f\"\\nâš™ï¸  Parameters: c={c}, Î³={gamma}, k={k}, kâ‚={k1}, w={window_size}\")\n",
    "    print(f\"ğŸ¨ Mode: {'Color (RGB)' if color else 'Grayscale'}\")\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    # Initialize TAPLA\n",
    "    tapla = TAPLAImageEnhancement(c, gamma, k, k1, window_size)\n",
    "    \n",
    "    # Statistics\n",
    "    results = {\n",
    "        'total': len(image_files),\n",
    "        'success': 0,\n",
    "        'failed': 0,\n",
    "        'total_time': 0,\n",
    "        'metrics': [],\n",
    "        'failed_files': []\n",
    "    }\n",
    "    \n",
    "    # Process each image with progress bar\n",
    "    for img_path in tqdm(image_files, desc=\"Processing images\"):\n",
    "        try:\n",
    "            filename = os.path.basename(img_path)\n",
    "            \n",
    "            # Load image\n",
    "            if color:\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is not None:\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            else:\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if img is None:\n",
    "                results['failed'] += 1\n",
    "                results['failed_files'].append(filename)\n",
    "                continue\n",
    "            \n",
    "            # Calculate original metrics\n",
    "            if color:\n",
    "                img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                img_gray = img\n",
    "            \n",
    "            orig_eme = tapla.calculate_eme(img_gray)\n",
    "            orig_ten = tapla.calculate_tenengrad(img_gray)\n",
    "            \n",
    "            # Enhance\n",
    "            start_time = time.time()\n",
    "            enhanced = tapla.enhance_image(img)\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # Calculate enhanced metrics\n",
    "            if color:\n",
    "                enh_gray = cv2.cvtColor(enhanced, cv2.COLOR_RGB2GRAY)\n",
    "            else:\n",
    "                enh_gray = enhanced\n",
    "            \n",
    "            enh_eme = tapla.calculate_eme(enh_gray)\n",
    "            enh_ten = tapla.calculate_tenengrad(enh_gray)\n",
    "            \n",
    "            # Save enhanced image\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            if color:\n",
    "                enhanced_bgr = cv2.cvtColor(enhanced, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(output_path, enhanced_bgr)\n",
    "            else:\n",
    "                cv2.imwrite(output_path, enhanced)\n",
    "            \n",
    "            # Store metrics\n",
    "            if save_metrics:\n",
    "                results['metrics'].append({\n",
    "                    'filename': filename,\n",
    "                    'orig_eme': orig_eme,\n",
    "                    'enh_eme': enh_eme,\n",
    "                    'eme_gain': ((enh_eme - orig_eme) / orig_eme * 100) if orig_eme > 0 else 0,\n",
    "                    'orig_ten': orig_ten,\n",
    "                    'enh_ten': enh_ten,\n",
    "                    'ten_gain': ((enh_ten - orig_ten) / orig_ten * 100) if orig_ten > 0 else 0,\n",
    "                    'time': elapsed_time\n",
    "                })\n",
    "            \n",
    "            results['success'] += 1\n",
    "            results['total_time'] += elapsed_time\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['failed'] += 1\n",
    "            results['failed_files'].append(f\"{filename} ({str(e)})\")\n",
    "    \n",
    "    # Save metrics to CSV\n",
    "    if save_metrics and len(results['metrics']) > 0:\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(results['metrics'])\n",
    "        csv_path = os.path.join(output_folder, 'enhancement_metrics.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        \n",
    "        # Save summary statistics\n",
    "        summary = {\n",
    "            'Total Images': results['total'],\n",
    "            'Successfully Processed': results['success'],\n",
    "            'Failed': results['failed'],\n",
    "            'Total Time (s)': f\"{results['total_time']:.2f}\",\n",
    "            'Average Time per Image (s)': f\"{results['total_time']/results['success']:.3f}\" if results['success'] > 0 else 0,\n",
    "            'Average EME Gain (%)': f\"{df['eme_gain'].mean():.2f}\",\n",
    "            'Average TEN Gain (%)': f\"{df['ten_gain'].mean():.2f}\"\n",
    "        }\n",
    "        \n",
    "        summary_df = pd.DataFrame([summary])\n",
    "        summary_path = os.path.join(output_folder, 'summary.csv')\n",
    "        summary_df.to_csv(summary_path, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"âœ… Successfully processed: {results['success']}/{results['total']} images\")\n",
    "    print(f\"âŒ Failed: {results['failed']} images\")\n",
    "    print(f\"â±ï¸  Total time: {results['total_time']:.2f}s\")\n",
    "    if results['success'] > 0:\n",
    "        print(f\"â±ï¸  Average time per image: {results['total_time']/results['success']:.3f}s\")\n",
    "    \n",
    "    if save_metrics and results['success'] > 0:\n",
    "        print(f\"\\nğŸ“Š Metrics saved to:\")\n",
    "        print(f\"   - {csv_path}\")\n",
    "        print(f\"   - {summary_path}\")\n",
    "        \n",
    "        # Print statistics\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(results['metrics'])\n",
    "        print(f\"\\nğŸ“ˆ Enhancement Statistics:\")\n",
    "        print(f\"   Average EME gain: {df['eme_gain'].mean():.2f}%\")\n",
    "        print(f\"   Average TEN gain: {df['ten_gain'].mean():.2f}%\")\n",
    "    \n",
    "    if results['failed'] > 0:\n",
    "        print(f\"\\nâš ï¸  Failed files:\")\n",
    "        for f in results['failed_files'][:10]:  # Show first 10\n",
    "            print(f\"   - {f}\")\n",
    "        if len(results['failed_files']) > 10:\n",
    "            print(f\"   ... and {len(results['failed_files'])-10} more\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def preview_batch_results(output_folder, num_samples=6):\n",
    "    \"\"\"\n",
    "    Preview random samples from batch processing results\n",
    "    \n",
    "    Parameters:\n",
    "        output_folder: folder containing enhanced images\n",
    "        num_samples: number of random images to display\n",
    "    \"\"\"\n",
    "    # Get all images in output folder\n",
    "    image_files = []\n",
    "    for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:\n",
    "        image_files.extend(glob.glob(os.path.join(output_folder, ext)))\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(f\"âŒ No images found in {output_folder}\")\n",
    "        return\n",
    "    \n",
    "    # Random sample\n",
    "    num_samples = min(num_samples, len(image_files))\n",
    "    sample_files = np.random.choice(image_files, num_samples, replace=False)\n",
    "    \n",
    "    # Display\n",
    "    cols = 3\n",
    "    rows = (num_samples + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "    axes = axes.flatten() if num_samples > 1 else [axes]\n",
    "    \n",
    "    for idx, img_path in enumerate(sample_files):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            if len(img.shape) == 3:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                axes[idx].imshow(img)\n",
    "            else:\n",
    "                axes[idx].imshow(img, cmap='gray')\n",
    "            \n",
    "            axes[idx].set_title(os.path.basename(img_path), fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    # Hide extra subplots\n",
    "    for idx in range(num_samples, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_batch_results(input_folder, output_folder, num_samples=3):\n",
    "    \"\"\"\n",
    "    Compare original vs enhanced images side by side\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder: folder with original images\n",
    "        output_folder: folder with enhanced images\n",
    "        num_samples: number of comparisons to show\n",
    "    \"\"\"\n",
    "    # Get common files\n",
    "    input_files = set([os.path.basename(f) for f in glob.glob(os.path.join(input_folder, '*.*'))])\n",
    "    output_files = set([os.path.basename(f) for f in glob.glob(os.path.join(output_folder, '*.*'))])\n",
    "    \n",
    "    # Exclude CSV files\n",
    "    common_files = list(input_files.intersection(output_files))\n",
    "    common_files = [f for f in common_files if not f.endswith('.csv')]\n",
    "    \n",
    "    if len(common_files) == 0:\n",
    "        print(\"âŒ No matching files found\")\n",
    "        return\n",
    "    \n",
    "    # Random sample\n",
    "    num_samples = min(num_samples, len(common_files))\n",
    "    sample_files = np.random.choice(common_files, num_samples, replace=False)\n",
    "    \n",
    "    # Display comparisons\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(12, 4*num_samples))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for idx, filename in enumerate(sample_files):\n",
    "        # Load original\n",
    "        orig_path = os.path.join(input_folder, filename)\n",
    "        orig = cv2.imread(orig_path)\n",
    "        if orig is not None and len(orig.shape) == 3:\n",
    "            orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load enhanced\n",
    "        enh_path = os.path.join(output_folder, filename)\n",
    "        enh = cv2.imread(enh_path)\n",
    "        if enh is not None and len(enh.shape) == 3:\n",
    "            enh = cv2.cvtColor(enh, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Display\n",
    "        cmap = None if len(orig.shape) == 3 else 'gray'\n",
    "        \n",
    "        axes[idx, 0].imshow(orig, cmap=cmap)\n",
    "        axes[idx, 0].set_title(f'Original: {filename}', fontsize=10)\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(enh, cmap=cmap)\n",
    "        axes[idx, 1].set_title(f'Enhanced: {filename}', fontsize=10)\n",
    "        axes[idx, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def create_sample_dataset(output_folder, num_images=10):\n",
    "    \"\"\"\n",
    "    Create sample dataset for testing batch processing\n",
    "    \n",
    "    Parameters:\n",
    "        output_folder: folder to save sample images\n",
    "        num_images: number of sample images to create\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    print(f\"Creating {num_images} sample images in {output_folder}...\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Create different types of test images\n",
    "        if i % 4 == 0:\n",
    "            # Low contrast\n",
    "            img = np.random.randint(80, 120, (256, 256, 3), dtype=np.uint8)\n",
    "        elif i % 4 == 1:\n",
    "            # Dark image\n",
    "            img = np.random.randint(0, 80, (256, 256, 3), dtype=np.uint8)\n",
    "        elif i % 4 == 2:\n",
    "            # Gradient\n",
    "            x = np.linspace(0, 255, 256)\n",
    "            y = np.linspace(0, 255, 256)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            img = np.stack([X, Y, (X+Y)/2], axis=2).astype(np.uint8)\n",
    "        else:\n",
    "            # Random\n",
    "            img = np.random.randint(0, 255, (256, 256, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Save\n",
    "        filename = f\"sample_{i+1:04d}.jpg\"\n",
    "        cv2.imwrite(os.path.join(output_folder, filename), img)\n",
    "    \n",
    "    print(f\"âœ“ Created {num_images} sample images\")\n",
    "    return output_folder\n",
    "    \"\"\"\n",
    "    Create sample test images\n",
    "    \"\"\"\n",
    "    images = {}\n",
    "    \n",
    "    # Low contrast image\n",
    "    images['low_contrast'] = np.random.randint(80, 120, (256, 256), dtype=np.uint8)\n",
    "    \n",
    "    # Dark image\n",
    "    dark_img = np.random.randint(0, 80, (256, 256), dtype=np.uint8)\n",
    "    images['dark'] = dark_img\n",
    "    \n",
    "    # Image with gradient\n",
    "    x = np.linspace(0, 255, 256)\n",
    "    y = np.linspace(0, 255, 256)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    images['gradient'] = ((X + Y) / 2).astype(np.uint8)\n",
    "    \n",
    "    # Checkerboard pattern\n",
    "    checker = np.zeros((256, 256), dtype=np.uint8)\n",
    "    checker[::32, ::32] = 200\n",
    "    checker[16::32, 16::32] = 200\n",
    "    images['checker'] = checker\n",
    "    \n",
    "    return images\n",
    "\n",
    "\n",
    "def plot_comparison(original, enhanced, params, metrics):\n",
    "    \"\"\"\n",
    "    Plot original vs enhanced with metrics\n",
    "    Supports both grayscale and color images\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    is_color = len(original.shape) == 3\n",
    "    cmap = None if is_color else 'gray'\n",
    "    \n",
    "    # Original image\n",
    "    axes[0, 0].imshow(original, cmap=cmap)\n",
    "    axes[0, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Enhanced image\n",
    "    axes[0, 1].imshow(enhanced, cmap=cmap)\n",
    "    axes[0, 1].set_title('TAPLA Enhanced', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Difference\n",
    "    diff = cv2.absdiff(original, enhanced)\n",
    "    if is_color:\n",
    "        # For color images, show difference as color\n",
    "        axes[0, 2].imshow(diff)\n",
    "    else:\n",
    "        # For grayscale, show as heatmap\n",
    "        im = axes[0, 2].imshow(diff, cmap='hot')\n",
    "        plt.colorbar(im, ax=axes[0, 2], fraction=0.046)\n",
    "    axes[0, 2].set_title('Absolute Difference', fontsize=12, fontweight='bold')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Histograms\n",
    "    if is_color:\n",
    "        # Color histograms for each channel\n",
    "        colors = ('r', 'g', 'b')\n",
    "        for i, col in enumerate(colors):\n",
    "            axes[1, 0].hist(original[:, :, i].ravel(), 256, [0, 256], \n",
    "                           color=col, alpha=0.5, label=col.upper())\n",
    "            axes[1, 1].hist(enhanced[:, :, i].ravel(), 256, [0, 256], \n",
    "                           color=col, alpha=0.5, label=col.upper())\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 1].legend()\n",
    "    else:\n",
    "        # Grayscale histograms\n",
    "        axes[1, 0].hist(original.ravel(), 256, [0, 256], color='blue', alpha=0.7)\n",
    "        axes[1, 1].hist(enhanced.ravel(), 256, [0, 256], color='green', alpha=0.7)\n",
    "    \n",
    "    axes[1, 0].set_title('Original Histogram', fontsize=12)\n",
    "    axes[1, 0].set_xlabel('Pixel Intensity')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 1].set_title('Enhanced Histogram', fontsize=12)\n",
    "    axes[1, 1].set_xlabel('Pixel Intensity')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Metrics text\n",
    "    axes[1, 2].axis('off')\n",
    "    metrics_text = f\"\"\"\n",
    "    PARAMETERS:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    c (brightness): {params['c']}\n",
    "    Î³ (contrast): {params['gamma']}\n",
    "    k (sharpness): {params['k']}\n",
    "    kâ‚ (threshold): {params['k1']}\n",
    "    window size: {params['window_size']}\n",
    "    \n",
    "    METRICS:\n",
    "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    Original EME: {metrics['orig_eme']:.2f}\n",
    "    Enhanced EME: {metrics['enh_eme']:.2f}\n",
    "    EME Gain: {metrics['eme_gain']:.2f}%\n",
    "    \n",
    "    Original TEN: {metrics['orig_ten']:.0f}\n",
    "    Enhanced TEN: {metrics['enh_ten']:.0f}\n",
    "    TEN Gain: {metrics['ten_gain']:.2f}%\n",
    "    \n",
    "    Time: {metrics['time']:.3f}s\n",
    "    \"\"\"\n",
    "    axes[1, 2].text(0.1, 0.5, metrics_text, fontsize=11, \n",
    "                    verticalalignment='center', fontfamily='monospace',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_tapla_experiment(img, c=1.0, gamma=1.5, k=2.0, k1=0.1, window_size=11):\n",
    "    \"\"\"\n",
    "    Run single TAPLA experiment\n",
    "    Supports both grayscale and color images\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"TAPLA IMAGE ENHANCEMENT EXPERIMENT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    params = {\n",
    "        'c': c,\n",
    "        'gamma': gamma,\n",
    "        'k': k,\n",
    "        'k1': k1,\n",
    "        'window_size': window_size\n",
    "    }\n",
    "    \n",
    "    is_color = len(img.shape) == 3\n",
    "    img_type = \"Color (RGB)\" if is_color else \"Grayscale\"\n",
    "    \n",
    "    print(f\"\\nImage size: {img.shape} ({img_type})\")\n",
    "    print(f\"Parameters: c={c}, Î³={gamma}, k={k}, kâ‚={k1}, w={window_size}\")\n",
    "    print(\"\\nProcessing...\")\n",
    "    \n",
    "    # Create TAPLA instance\n",
    "    tapla = TAPLAImageEnhancement(**params)\n",
    "    \n",
    "    # Calculate original metrics (convert to grayscale for metrics if color)\n",
    "    if is_color:\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        img_gray = img\n",
    "    \n",
    "    orig_eme = tapla.calculate_eme(img_gray)\n",
    "    orig_ten = tapla.calculate_tenengrad(img_gray)\n",
    "    \n",
    "    # Enhance image\n",
    "    start_time = time.time()\n",
    "    enhanced = tapla.enhance_image(img)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate enhanced metrics\n",
    "    if is_color:\n",
    "        enhanced_gray = cv2.cvtColor(enhanced, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        enhanced_gray = enhanced\n",
    "    \n",
    "    enh_eme = tapla.calculate_eme(enhanced_gray)\n",
    "    enh_ten = tapla.calculate_tenengrad(enhanced_gray)\n",
    "    \n",
    "    # Calculate gains\n",
    "    eme_gain = ((enh_eme - orig_eme) / orig_eme) * 100 if orig_eme > 0 else 0\n",
    "    ten_gain = ((enh_ten - orig_ten) / orig_ten) * 100 if orig_ten > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'orig_eme': orig_eme,\n",
    "        'enh_eme': enh_eme,\n",
    "        'eme_gain': eme_gain,\n",
    "        'orig_ten': orig_ten,\n",
    "        'enh_ten': enh_ten,\n",
    "        'ten_gain': ten_gain,\n",
    "        'time': elapsed_time\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nâœ“ Enhancement completed in {elapsed_time:.3f}s\")\n",
    "    print(f\"  EME: {orig_eme:.2f} â†’ {enh_eme:.2f} ({eme_gain:+.1f}%)\")\n",
    "    print(f\"  TEN: {orig_ten:.0f} â†’ {enh_ten:.0f} ({ten_gain:+.1f}%)\")\n",
    "    \n",
    "    # Plot results\n",
    "    plot_comparison(img, enhanced, params, metrics)\n",
    "    \n",
    "    return enhanced, metrics\n",
    "\n",
    "\n",
    "def compare_multiple_params(img, params_list):\n",
    "    \"\"\"\n",
    "    Compare multiple parameter sets\n",
    "    \"\"\"\n",
    "    n_params = len(params_list)\n",
    "    results = []\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(f\"COMPARING {n_params} DIFFERENT PARAMETER SETS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Calculate original metrics once\n",
    "    tapla = TAPLAImageEnhancement()\n",
    "    orig_eme = tapla.calculate_eme(img)\n",
    "    orig_ten = tapla.calculate_tenengrad(img)\n",
    "    \n",
    "    for i, params in enumerate(params_list):\n",
    "        print(f\"\\n[{i+1}/{n_params}] Processing with: c={params['c']}, Î³={params['gamma']}, \"\n",
    "              f\"k={params['k']}, kâ‚={params['k1']}\")\n",
    "        \n",
    "        tapla = TAPLAImageEnhancement(**params)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        enhanced = tapla.enhance_image(img)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        enh_eme = tapla.calculate_eme(enhanced)\n",
    "        enh_ten = tapla.calculate_tenengrad(enhanced)\n",
    "        \n",
    "        results.append({\n",
    "            'params': params,\n",
    "            'enhanced': enhanced,\n",
    "            'eme': enh_eme,\n",
    "            'ten': enh_ten,\n",
    "            'time': elapsed_time\n",
    "        })\n",
    "        \n",
    "        print(f\"  Time: {elapsed_time:.3f}s | EME: {enh_eme:.2f} | TEN: {enh_ten:.0f}\")\n",
    "    \n",
    "    # Visualization\n",
    "    fig = plt.figure(figsize=(18, 10))\n",
    "    \n",
    "    # Original image\n",
    "    ax = plt.subplot(3, n_params + 1, 1)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f'Original\\nEME: {orig_eme:.1f}\\nTEN: {orig_ten:.0f}', \n",
    "                 fontsize=10, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    ax = plt.subplot(3, n_params + 1, n_params + 2)\n",
    "    ax.hist(img.ravel(), 256, [0, 256], color='gray', alpha=0.7)\n",
    "    ax.set_title('Original Histogram', fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    ax = plt.subplot(3, n_params + 1, 2*n_params + 3)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Enhanced images\n",
    "    for i, result in enumerate(results):\n",
    "        # Image\n",
    "        ax = plt.subplot(3, n_params + 1, i + 2)\n",
    "        ax.imshow(result['enhanced'], cmap='gray')\n",
    "        ax.set_title(f\"TAPLA {i+1}\\n\"\n",
    "                    f\"EME: {result['eme']:.1f} | TEN: {result['ten']:.0f}\\n\"\n",
    "                    f\"Time: {result['time']:.3f}s\", \n",
    "                    fontsize=9)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Histogram\n",
    "        ax = plt.subplot(3, n_params + 1, n_params + 3 + i)\n",
    "        ax.hist(result['enhanced'].ravel(), 256, [0, 256], \n",
    "                color=f'C{i}', alpha=0.7)\n",
    "        ax.set_title(f\"Histogram {i+1}\", fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Parameters\n",
    "        ax = plt.subplot(3, n_params + 1, 2*n_params + 4 + i)\n",
    "        ax.axis('off')\n",
    "        param_text = (f\"c={result['params']['c']}\\n\"\n",
    "                     f\"Î³={result['params']['gamma']}\\n\"\n",
    "                     f\"k={result['params']['k']}\\n\"\n",
    "                     f\"kâ‚={result['params']['k1']}\\n\"\n",
    "                     f\"w={result['params']['window_size']}\")\n",
    "        ax.text(0.5, 0.5, param_text, fontsize=9, ha='center', va='center',\n",
    "                bbox=dict(boxstyle='round', facecolor=f'C{i}', alpha=0.3))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EXAMPLE USAGE IN JUPYTER NOTEBOOK\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘       TAPLA Image Enhancement - Jupyter Notebook Version             â•‘\n",
    "â•‘  Threshold-based Adaptive Power-Law Applications                     â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Quick Start Examples:\n",
    "\n",
    "1. BATCH PROCESSING (1000 images):\n",
    "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "   # Process entire folder\n",
    "   results = batch_enhance_images(\n",
    "       input_folder='./input_images',\n",
    "       output_folder='./enhanced_images',\n",
    "       c=1.5, gamma=0.56, k=2.0, k1=0.2,\n",
    "       color=True  # Set False for grayscale\n",
    "   )\n",
    "   \n",
    "   # Preview results\n",
    "   preview_batch_results('./enhanced_images', num_samples=6)\n",
    "   \n",
    "   # Compare original vs enhanced\n",
    "   compare_batch_results('./input_images', './enhanced_images', num_samples=3)\n",
    "\n",
    "2. Upload and enhance single image (Google Colab):\n",
    "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "   filename = upload_image_jupyter()\n",
    "   \n",
    "   # For COLOR image:\n",
    "   img = load_image(filename, color=True)\n",
    "   enhanced, metrics = run_tapla_experiment(img, c=1.5, gamma=0.56, k=2.0, k1=0.2)\n",
    "\n",
    "2. Use sample images (no upload needed):\n",
    "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "   # Create test dataset\n",
    "   create_sample_dataset('./test_images', num_images=10)\n",
    "   \n",
    "   # Process all images\n",
    "   results = batch_enhance_images('./test_images', './output', color=True)\n",
    "\n",
    "3. Compare multiple parameter sets:\n",
    "   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "   img = load_image('image.jpg', color=True)\n",
    "   params_list = [\n",
    "       {'c': 1.0, 'gamma': 2.5, 'k': 2.0, 'k1': 0.06, 'window_size': 11},\n",
    "       {'c': 1.0, 'gamma': 1.1, 'k': 4.0, 'k1': 0.06, 'window_size': 11},\n",
    "       {'c': 2.0, 'gamma': 1.5, 'k': -1.0, 'k1': 0.1, 'window_size': 11}\n",
    "   ]\n",
    "   results = compare_multiple_params(img, params_list)\n",
    "\n",
    "BATCH PROCESSING TIPS:\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "â€¢ Supports: .jpg, .jpeg, .png, .bmp\n",
    "â€¢ Auto-saves metrics to CSV\n",
    "â€¢ Progress bar shows real-time status\n",
    "â€¢ Handles errors gracefully\n",
    "â€¢ Creates output folder automatically\n",
    "\n",
    "Parameter Guide:\n",
    "   c      : brightness (typically 1.0-2.0)\n",
    "   gamma  : contrast (>1 increase, <1 decrease)\n",
    "   k      : sharpness (positive) or smoothness (negative)\n",
    "   k1     : threshold control [0, 1]\n",
    "   \n",
    "Ready to use! ğŸš€\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f48f1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BATCH TAPLA IMAGE ENHANCEMENT\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ Input folder:  D:\\\\Huce\\\\XLA\\\\LoLI-Street Dataset\\\\Test_50img_LL\n",
      "ğŸ“ Output folder: D:\\\\Huce\\\\XLA\\\\LoLI-Street Dataset\\\\Results_40Img_LL\n",
      "ğŸ–¼ï¸  Found 80 images\n",
      "\n",
      "âš™ï¸  Parameters: c=1.5, Î³=0.56, k=2.0, kâ‚=0.18, w=11\n",
      "ğŸ¨ Mode: Color (RGB)\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637d5072eb464f62a6d0b6a8e907b96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "ğŸ¨ Processing color image (R, G, B channels separately)...\n",
      "   Channel R... âœ“\n",
      "   Channel G... âœ“\n",
      "   Channel B... âœ“\n",
      "\n",
      "======================================================================\n",
      "PROCESSING COMPLETE\n",
      "======================================================================\n",
      "âœ… Successfully processed: 80/80 images\n",
      "âŒ Failed: 0 images\n",
      "â±ï¸  Total time: 1018.44s\n",
      "â±ï¸  Average time per image: 12.730s\n",
      "\n",
      "ğŸ“Š Metrics saved to:\n",
      "   - D:\\\\Huce\\\\XLA\\\\LoLI-Street Dataset\\\\Results_40Img_LL\\enhancement_metrics.csv\n",
      "   - D:\\\\Huce\\\\XLA\\\\LoLI-Street Dataset\\\\Results_40Img_LL\\summary.csv\n",
      "\n",
      "ğŸ“ˆ Enhancement Statistics:\n",
      "   Average EME gain: -17.56%\n",
      "   Average TEN gain: 3017.34%\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "results = batch_enhance_images(\n",
    "       input_folder=r'D:\\\\Huce\\\\XLA\\\\LoLI-Street Dataset\\\\Test_50img_LL',\n",
    "       output_folder=r\"D:\\\\Huce\\\\XLA\\\\LoLI-Street Dataset\\\\Results_40Img_LL\",\n",
    "       c=1.5, gamma=0.56, k=2.0, k1=0.18,\n",
    "       color=True  # Set False for grayscale\n",
    "   )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
